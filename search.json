[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DS QuickRef",
    "section": "",
    "text": "About\nThis book is a quick-reference guide for data science, machine learning, and related topics. It’s written for students and working professionals who want a practical summary of key ideas, workflows, and tools.\nThis guide focuses on quick definitions, examples, short reminders, and curated links. It’s meant to be used when:\n\nYou’ve already learned a concept and need a quick refresher.\nYou’re working on a project and want to check best practices.\nYou forgot which metrics apply to a specific ML task.\nYou want a shortcut to useful external resources.\n\nThis guide is a work in progress and will grow over time as I add new topics and improve existing ones.\nThe field is wide, and no two data scientists use the exact same approach or tools. This guide reflects a generalist perspective, based on real-world use cases and common patterns.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "common_issues.html",
    "href": "common_issues.html",
    "title": "Common Issues in Data Science",
    "section": "",
    "text": "Data",
    "crumbs": [
      "Common Issues in Data Science"
    ]
  },
  {
    "objectID": "common_issues.html#data",
    "href": "common_issues.html#data",
    "title": "Common Issues in Data Science",
    "section": "",
    "text": "Problem\nSolution\n\n\n\n\nNot enough data\nUse data augmentation or synthetic sampling (e.g. SMOTE, SDV)\n\n\nData not representative of the distribution\nReassess how data was collected; consider stratified sampling\n\n\nImbalanced classes\nTry resampling, adjusting class weights, or adding synthetic data with SDV\n\n\nToo much data (examples)\nSubsample or use mini-batch training; profile before full-scale training\n\n\nToo many features / high dimensionality\nApply feature selection or dimensionality reduction (e.g. PCA)\n\n\nData has extreme values, outliers, or anomalies\nUse robust statistics, or find such values using outlier/anomaly detection methods. Consider removing examples.\n\n\nData may have been faked\nCheck for duplicate rows, unnatural distributions, and value repetition\n\n\nData leakage\nReview data sources and pipeline; make sure target isn’t leaking into features",
    "crumbs": [
      "Common Issues in Data Science"
    ]
  },
  {
    "objectID": "common_issues.html#modeling",
    "href": "common_issues.html#modeling",
    "title": "Common Issues in Data Science",
    "section": "Modeling",
    "text": "Modeling\n\n\n\n\n\n\n\nProblem\nSolution\n\n\n\n\nModel performs well on training, terrible on test (overfitting)\nReduce model complexity, add regularization, or get more data\n\n\nModel performs poorly on training AND test data (underfitting)\nUse a more complex model, add better features, reduce regularization.\n\n\nClassification model worse than a random guess or worse than majority class guess\nInvestigate data quality, imbalanced classes.\n\n\nModel performs unusually well on train and test data\nCheck for data leakage; the model may have access to information it shouldn’t.",
    "crumbs": [
      "Common Issues in Data Science"
    ]
  },
  {
    "objectID": "common_issues.html#workflow",
    "href": "common_issues.html#workflow",
    "title": "Common Issues in Data Science",
    "section": "Workflow",
    "text": "Workflow\n\n\n\n\n\n\n\nProblem\nSolution\n\n\n\n\nJupyter notebook is too large\nAvoid storing large Plotly outputs; clean outputs or split the notebook\n\n\nModel training takes too long\nUse smaller subsets for tuning; simplify the model or parallelize training",
    "crumbs": [
      "Common Issues in Data Science"
    ]
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Explainability\nOversampling\nOverfitting and Underfitting\nData leakage\nFeatures\nReinforcement learning\nSupervised learning\nUnsupervised learning\nDescriptive statistics\nDeep learning\nDistribution\nProbability",
    "crumbs": [
      "Glossary"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "A collection of useful resources and tools.\n\nConcepts\n\nExplainability\n\nInterpretable Machine Learning: A practical overview of techniques for making ML models more transparent, including SHAP, LIME, and model-specific tools.\nSHAP Documentation: Official docs for SHAP (SHapley Additive exPlanations), a method to interpret the output of machine learning models.\n\n\n\nVisualization\n\nUW Interactive Data Lab Curriculum: Visualization using Vega-Lite and Altair.\nFundamentals of Data Visualization: Principles and examples of clear, effective visual communication.\n\n\n\nTime Series\n\nForecasting: Principles and Practice: Covers forecasting techniques like exponential smoothing and ARIMA, with examples in R.\n\n\n\nData Imputation\n\nFlexible Imputation of Missing Data: Methods to handle missing data, with emphasis on multiple imputation.\n\n\n\nFraud Detection\n\nFraud Detection Handbook: Applied techniques for detecting fraud in highly imbalanced, real-world datasets. Includes examples and code.\n\n\n\n\nTools\n\nSDV - Python library for creating tabular synthetic data.\n\n\n\nResources used to make this guide\n\nQuarto: Publishing system. Supports notebooks, markdown, citations, and publishing to HTML and PDF.\nbootswatch: Collection of free themes for Bootstrap-based sites (used to style this book).",
    "crumbs": [
      "References"
    ]
  }
]