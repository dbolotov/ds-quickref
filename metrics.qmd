# Data Science and Machine Learning Metrics {.unnumbered}

This page is a quick reference for common metrics across tasks like classification, regression, and clustering. Each entry includes a definition, when to use it, and links to an explanation (mostly from Wikipedia) and the relevant scikit-learn doc. This list is not meant to be exhaustive.

## What Are Metrics?

A **metric** is a number that measures model performance, or how well predictions match actual outcomes.

- In **supervised learning**, metrics evaluate prediction quality (e.g. RMSE, F1).
- In **unsupervised learning**, they assess structure or similarity (e.g. silhouette score).
- During training, metrics guide choices like model selection and early stopping.

### Related terms

- **Loss function**: What the model *optimizes* during training.
- **Metric**: What you *monitor* to evaluate results.
- **Error metric**: Often used in regression to describe prediction error.



### Classification

#### Regression

::: {.small-table}

| Metric | sklearn | Details |
|--------|---------|---------|
| [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) | [link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) | **Mean Squared Error**. Average squared difference between predictions and true values. Penalizes larger errors more; sensitive to outliers. Not in original units. |
| [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) | [link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html) | **Root Mean Squared Error**. Same as MSE but in the original unit scale; easier to interpret. Still sensitive to outliers. |
| [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) | [link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) | **Mean Absolute Error**. Average absolute difference between predictions and actual values. More robust to outliers than MSE. |
| [R²](https://en.wikipedia.org/wiki/Coefficient_of_determination) | [link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) | **Coefficient of Determination**. Measures proportion of variance explained by the model. Can be negative. |
| [Adjusted R²](https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2) | *(not built-in)* | **Adjusted R²**. Like R² but penalizes for additional predictors. Helps avoid overfitting. Must be computed manually. |
| [MSLE](https://permetrics.readthedocs.io/en/latest/pages/regression/MSLE.html) | [link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html) | **Mean Squared Log Error**. MSE on log-transformed targets. Good for targets spanning orders of magnitude. |
| [MAPE](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error) | [link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html) | **Mean Absolute Percentage Error**. Average of absolute percentage errors. Can blow up if targets are near zero. |
| [SMAPE](https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error) | *(not built-in)* | **Symmetric MAPE**. Like MAPE but less sensitive to small denominators. Often used in time series. Must implement manually. |

:::
